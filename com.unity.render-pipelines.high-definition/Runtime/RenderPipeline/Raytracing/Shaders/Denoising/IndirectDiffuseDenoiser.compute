#pragma kernel ConvertRGBToYCoCg
#pragma kernel ConvertYCoCgToRGB
#pragma kernel ValidateHistory
#pragma kernel TemporalAccumulation
#pragma kernel CopyHistory
#pragma kernel BilateralFilterNoNormal BILATERAL_FILTER=BilateralFilterNoNormal IGNORE_NORMAL
#pragma kernel BilateralFilter BILATERAL_FILTER=BilateralFilter

// Common includes
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/CommonLighting.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Sampling.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"

// HDRP includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/NormalBuffer.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/PostProcessing/Shaders/TemporalAntialiasing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/Denoising/BilateralFilter.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"

#pragma only_renderers d3d11
// #pragma enable_d3d11_debug_symbols

// Tile size of this compute shaders
#define TEMPORAL_FILTER_TILE_SIZE 8

// Depth buffer of the previous frame
TEXTURE2D_X(_HistoryDepthTexture);
// Normal buffer of the previous frame
TEXTURE2D_X(_HistoryNormalBufferTexture);
// Buffer that stores the result of the validation pass of the history
RW_TEXTURE2D_X(float, _ValidationBufferRW);
// This holds the fov angle of a pixel
float _PixelSpreadAngleTangent;
// Value that tells us if the current history should be discarded based on scene-level data
float _HistoryValidity;
// Radius of the filter (world space)
float _DenoiserFilterRadius;

// The maximal world space distance for temporal reprojection
#define MAX_WORLD_SPACE_DISTANCE 0.75
// The maximal pixel reprojection distance
#define PIXEL_RADIUS_TOLERANCE_THRESHOLD 8
// The maximal normal difference threshold
#define MAX_NORMAL_DIFFERENCE 0.65
// Number of samples to compelte the accumulation loop
#define NUM_SAMPLE_LOOP 16.0
#define EXPONENTIAL_ACCUMULATION_FACTOR (NUM_SAMPLE_LOOP/(NUM_SAMPLE_LOOP + 1.0f))

[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void ValidateHistory(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinates
    uint2 centerCoord = groupId * TEMPORAL_FILTER_TILE_SIZE + groupThreadId;

    // Get the posinputs of the current version of the pixel
    float depth = LOAD_TEXTURE2D_X(_DepthTexture, centerCoord).r;
    PositionInputs posInputs = GetPositionInput(centerCoord, _ScreenSize.zw, depth, UNITY_MATRIX_I_VP, GetWorldToViewMatrix());

    // If the current point we are processing is a background point or the whole history should be discarded for an other reason, we invalidate the history
    if (depth == UNITY_RAW_FAR_CLIP_VALUE || _HistoryValidity == 0.0f)
    {
        _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 0;
        return;
    }

    // Decode the velocity of the pixel
    float2 velocity = float2(0.0, 0.0);
    DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture, (float2)centerCoord), velocity);

    // Compute the pixel coordinate for the history tapping
    int2 historyTapCoord = (int2)((posInputs.positionNDC - velocity) * _ScreenSize.xy);

    // If the pixel was outside of the screen during the previous frame, invalidate the history
    if (historyTapCoord.x > _ScreenSize.x || historyTapCoord.x < 0 || historyTapCoord.y > _ScreenSize.y || historyTapCoord.y < 0)
    {
        _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 0;
        return;
    }

    // Fetch the depth of the history pixel. If the history position was a background point, invalidate the history
    float historyDepth = LOAD_TEXTURE2D_X(_HistoryDepthTexture, historyTapCoord).r;
    if (historyDepth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 0;
        return;
    }


    // Real the normal data for this pixel
    NormalData normalData;
    DecodeFromNormalBuffer(centerCoord, normalData);

    // Compute the world space position (from previous frame)
    float3 historyPositionWS = ComputeWorldSpacePosition(posInputs.positionNDC - velocity, historyDepth, UNITY_MATRIX_PREV_I_VP);

    // Compute the max reprojection distance. This is evaluated as the max between a fixed radius value and an approximation of the footprint of the pixel.
    float3 viewWS = normalize(-posInputs.positionWS);
    float parallelPixelFootPrint = _PixelSpreadAngleTangent * length(posInputs.positionWS);
    float realPixelFootPrint = parallelPixelFootPrint / abs(dot(normalData.normalWS, viewWS));
    float maxRadius = max(MAX_WORLD_SPACE_DISTANCE, realPixelFootPrint * PIXEL_RADIUS_TOLERANCE_THRESHOLD);

    // Is it too far from the current position?
    if (length(historyPositionWS - posInputs.positionWS) > maxRadius)
    {
        _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 0;
        return;
    }

    // Compute the world space normal (from previous frame)
    float4 historyNormal = LOAD_TEXTURE2D_X(_HistoryNormalBufferTexture, historyTapCoord);
    NormalData historyNormalData;
    DecodeFromNormalBuffer(historyNormal, uint2(0,0), historyNormalData);
    
    // If the current normal is too different from the previous one, discard the history.
    if (dot(normalData.normalWS, historyNormalData.normalWS) < MAX_NORMAL_DIFFERENCE)
    {
        _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 0;
        return;
    }

    // If none of the previous conditions have failed, the the history is valid
    _ValidationBufferRW[COORD_TEXTURE2D_X(centerCoord)] = 1;
}

// Validation buffer that tells us if the history should be ignored for a given pixel.
TEXTURE2D_X(_ValidationBuffer);
// This buffer holds the previously accumualted signal
TEXTURE2D_X(_HistoryBuffer0);
TEXTURE2D_X(_HistoryBuffer1);
// Noisy Input Buffer from the current rame
TEXTURE2D_X(_DenoiseInputTexture0);
TEXTURE2D_X(_DenoiseInputTexture1);
// Generic output buffer for our kernels
RW_TEXTURE2D_ARRAY(float4, _DenoiseOutputTexture0RW);
RW_TEXTURE2D_ARRAY(float4, _DenoiseOutputTexture1RW);

TEXTURE2D_X(_DirectionTexture);

void RGBToYCoCgUtil(float3 inColor, float3 inDirection, out float4 outYSH, out float2 outCoCg)
{
    // Convert the color to ycocg space
    float3 yCoCg = RGBToYCoCg(inColor);

    // Compute the coeffs required for the projection
    float Y00     = 0.282095;
    float Y11     = 0.488603 * inDirection.x;
    float Y10     = 0.488603 * inDirection.z;
    float Y1_1    = 0.488603 * inDirection.y;

    // Output the values
    outYSH.x = yCoCg.x * Y00;
    outYSH.y = yCoCg.x * Y11;
    outYSH.z = yCoCg.x * Y10;
    outYSH.w = yCoCg.x * Y1_1;
    outCoCg.x = yCoCg.y;
    outCoCg.y = yCoCg.z;
}

[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void ConvertRGBToYCoCg(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinate
    uint2 centerCoord = groupId * TEMPORAL_FILTER_TILE_SIZE + groupThreadId;

    // If the depth of this pixel is the depth of the background, we can end the process right away
    float depth = LOAD_TEXTURE2D_X(_DepthTexture, centerCoord).r;
    if (depth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 0);
        return;
    }
    // Fetch the current value, history value and current sample count
    float3 color = LOAD_TEXTURE2D_X(_DenoiseInputTexture0, centerCoord).xyz;
    float3 direction = LOAD_TEXTURE2D_X(_DirectionTexture, centerCoord).xyz;

    // Convert the color we got
    float4 ySH;
    float2 cocg;
    RGBToYCoCgUtil(color, direction, ySH, cocg);

    // Store our accumulated value
    _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = ySH;
    _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(centerCoord)] = float4(cocg, 0.0, 0.0);
}

void ConvertYCoCgToRGBUtil(float4 inYSH, float2 inCoCg, float3 inNormal, out float3 outColor)
{
    // Compute the coeffs required for the projection
    float Y00     = 0.282095;
    float Y11     = 0.488603 * inNormal.x;
    float Y10     = 0.488603 * inNormal.z;
    float Y1_1    = 0.488603 * inNormal.y;

    // Compute the Y value
    float y = 3.141593 * Y00 * inYSH.x
                + 2.094395 * Y1_1 * inYSH.w
                + 2.094395 * Y10 * inYSH.z
                + 2.094395 * Y11 * inYSH.y;

    // Compute the output color
    outColor = y != 0.0 ? YCoCgToRGB(float3(y, inCoCg.xy)) : 0.0;
    outColor = max(outColor, 0.0);
}

[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void ConvertYCoCgToRGB(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinate
    uint2 centerCoord = groupId * TEMPORAL_FILTER_TILE_SIZE + groupThreadId;

    // If the depth of this pixel is the depth of the background, we can end the process right away
    float depth = LOAD_TEXTURE2D_X(_DepthTexture, centerCoord).r;
    if (depth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 0);
        return;
    }

    NormalData normalData;
    DecodeFromNormalBuffer(centerCoord, normalData);

    // Convert the color we got
    float3 color;
    float4 ySH = LOAD_TEXTURE2D_X(_DenoiseInputTexture0, centerCoord);
    float2 cocg = LOAD_TEXTURE2D_X(_DenoiseInputTexture1, centerCoord).xy;
    ConvertYCoCgToRGBUtil(ySH, cocg, normalData.normalWS, color);

    // Store our accumulated value
    _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = float4(color, 1.0);
}

[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void TemporalAccumulation(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinate
    uint2 centerCoord = groupId * TEMPORAL_FILTER_TILE_SIZE + groupThreadId;

    // If the depth of this pixel is the depth of the background, we can end the process right away
    float depth = LOAD_TEXTURE2D_X(_DepthTexture, centerCoord).r;
    if (depth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 0);
        _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 0);
        return;
    }

    // Fetch the position of the current pixel
    PositionInputs posInputs = GetPositionInput(centerCoord, _ScreenSize.zw, depth, UNITY_MATRIX_I_VP, GetWorldToViewMatrix());

    // Compute the velocity information for this pixel
    float2 velocity = float2(0.0, 0.0);
    DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture, (float2)centerCoord), velocity);
    uint2 historyTapCoord = (uint2)((posInputs.positionNDC - velocity) * _ScreenSize.xy);

    // Fetch the current value, history value and current sample count
    float4 ySH = LOAD_TEXTURE2D_X(_DenoiseInputTexture0, centerCoord);
    float2 cocg = LOAD_TEXTURE2D_X(_DenoiseInputTexture1, centerCoord).xy;
    float4 history0 = LOAD_TEXTURE2D_X(_HistoryBuffer0, historyTapCoord);
    float4 history1 = LOAD_TEXTURE2D_X(_HistoryBuffer1, historyTapCoord);
    float sampleCount = history1.z;

    // Accumulation factor that tells us how much we need to keep the history data
    float accumulationFactor = 0.0;

    // If the history is invalid
    if (_ValidationBuffer[COORD_TEXTURE2D_X(centerCoord)].x < 1.0 )
    {
        // We only take the current value
        accumulationFactor = 0.0;
        // And the sample count of history becomes 1 (or 0 if the previous sample was mooving)
        sampleCount = 1.0;
    }
    else
    {
        // Otherwise we compute the accumulation factor
        accumulationFactor = sampleCount >= NUM_SAMPLE_LOOP ? EXPONENTIAL_ACCUMULATION_FACTOR : (sampleCount / (sampleCount + 1.0));
        // Update the sample count
        sampleCount = min(sampleCount + 1.0, NUM_SAMPLE_LOOP);
    }

    // Store our accumulated value
    _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = ySH * (1.0 - accumulationFactor) + history0 * accumulationFactor;
    _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(centerCoord)] = float4(cocg * (1.0 - accumulationFactor) + history1.xy * accumulationFactor, sampleCount, 0.0);
}
    
[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void CopyHistory(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    if (any(dispatchThreadId.xy > uint2(_ScreenSize.xy)))
        return;  // Out of bounds, discard

    _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = LOAD_TEXTURE2D_X(_DenoiseInputTexture0, dispatchThreadId.xy);
    _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = LOAD_TEXTURE2D_X(_DenoiseInputTexture1, dispatchThreadId.xy);
}

[numthreads(TEMPORAL_FILTER_TILE_SIZE, TEMPORAL_FILTER_TILE_SIZE, 1)]
void BILATERAL_FILTER(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinate
    uint2 centerCoord = groupId * TEMPORAL_FILTER_TILE_SIZE + groupThreadId;

    // Read the central position
    const BilateralData center = TapBilateralData(centerCoord);

    // If this is a background pixel, we are done
    if (center.z01 == 1.0)
    {
        _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 1.0);
        _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(centerCoord)] = float4(0.0, 0.0, 0.0, 1.0);
    }

    // Create the local ortho basis for our sampling
    float3x3 localToWorld = GetLocalFrame(center.normal);

    // Intialize the accumulation values
    float4 colorSum0 = 0.0;
    float2 colorSum1 = 0.0;
    float wSum = 0.0;

    // Define the sample count for this pixel. 16 samples per pixels if it is a full res or 4 if half resolution
    int numSamples = 48;

    // Compute the radius of the filter. This is evaluated as the max between a fixed radius value and an approximation of the footprint of the pixel
    const float parallelPixelFootPrint = _PixelSpreadAngleTangent * length(center.position);
    const float3 viewWS = normalize(-center.position);
    const float realPixelFootPrint = parallelPixelFootPrint / abs(dot(center.normal, viewWS));
    const float denoisingRadius = max(_DenoiserFilterRadius, realPixelFootPrint * PIXEL_RADIUS_TOLERANCE_THRESHOLD);

    // Compute the sigma value
    const float sigma = 0.5 * denoisingRadius;

    // Index of the pixel in the 2x2 group that are used for the half res filter
    int localIndex = (centerCoord.x & 1) + (centerCoord.y & 1) * 2;

    // Loop through the samples that we need to aggrgate
    for (uint sampleIndex = 0; sampleIndex < (uint)numSamples; ++sampleIndex)
    {
        // Fetch the noise value for the current sample
        float2 newSample;
        newSample.x = GetLDSequenceSampleFloat(sampleIndex, 0);
        newSample.y = GetLDSequenceSampleFloat(sampleIndex, 1);
        
        // Convert the sample to a local unit disk
        newSample = SampleDiskUniform(newSample.x * newSample.x, newSample.y);

        // Distribute them according a square profile
        newSample *= denoisingRadius * denoisingRadius;

        // Convert the point to hemogenous clip space
        float3 wsPos = center.position + localToWorld[0] * newSample.x + localToWorld[1] * newSample.y;
        float4 hClip = TransformWorldToHClip(wsPos);
        hClip.xyz /= hClip.w;

        // Is the target pixel in the screen?
        if (hClip.x > 1.0 || hClip.x < -1.0 || hClip.y > 1.0 || hClip.y < -1.0 )
            continue;

        // Convert it to screen sample space
        float2 nDC = hClip.xy * 0.5 + 0.5;
    #if UNITY_UV_STARTS_AT_TOP
        nDC.y = 1.0 - nDC.y;
    #endif

        // Tap the data for this pixel
        uint2 tapCoord = nDC * _ScreenSize.xy;
        const BilateralData tapData = TapBilateralData(tapCoord);

        // If the tapped pixel is a background pixel or too far from the center pixel
        if (tapData.z01 == UNITY_RAW_FAR_CLIP_VALUE || abs(tapData.zNF - hClip.w) > 0.1)
            continue;

        // Compute the radius of the sample
        float r = length(newSample);

        // Compute the weight (skip computation for the center)
        const float w = r > 0.001f ? gaussian(r, sigma) * ComputeBilateralWeight(center, tapData) : 1.0;

        // Accumulate the new sample
        colorSum0 += LOAD_TEXTURE2D_X(_DenoiseInputTexture0, tapCoord).xyzw * w;
        colorSum1 += LOAD_TEXTURE2D_X(_DenoiseInputTexture1, tapCoord).xy * w;
        wSum += w;
    }

    // If no samples were found, we take the center pixel only
    if (wSum == 0.0)
    {
        colorSum0 += LOAD_TEXTURE2D_X(_DenoiseInputTexture0, centerCoord).xyzw;
        colorSum1 += LOAD_TEXTURE2D_X(_DenoiseInputTexture1, centerCoord).xy;
        wSum += 1.0;
    }

    // Normalize the result
    _DenoiseOutputTexture0RW[COORD_TEXTURE2D_X(centerCoord)] = colorSum0 / wSum;
    _DenoiseOutputTexture1RW[COORD_TEXTURE2D_X(centerCoord)] = float4(colorSum1 / wSum, 0.0, 1.0);
}
