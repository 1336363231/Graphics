#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"

#pragma kernel KMain

#pragma multi_compile FILTER_BOX FILTER_GAUSSIAN FILTER_TRIANGLE FILTER_CATMULLROM

// Inputs
TEXTURE2D_X(_RadianceTexture);
float4      _AccumulationWeights;
int         _AccumulationNeedsExposure;
uint        _AccumulationFrameIndex;
uint        _AccumulationNumSamples;

// Input - Output(s)
RW_TEXTURE2D_X(float4,  _CameraColorTextureRW);
RW_TEXTURE2D_X(float4,  _AccumulatedFrameTexture);

void AddConvergenceCue(uint2 pixelCoord, uint sampleCount, inout float3 color)
{
    // If we reached 100%, do not display the bar anymore
    if (sampleCount >= _AccumulationNumSamples)
        return;

    uint width = _ScreenSize.x;
    uint height = _ScreenSize.y;

    // Change color only in a region corresponding to a progress bar, on the bottom 1% of the screen
    if (pixelCoord.y < 4 && (float)pixelCoord.x / width <= (float)sampleCount / _AccumulationNumSamples)
    {
        float lum = Luminance(color);

        if (lum > 1.0)
        {
            color /= lum;
            lum = 1.0;
        }

        // Make dark color brighter, and vice versa
        color += lum > 0.5 ? -0.5 * lum : 0.05 + 0.5 * lum;
    }
}

float GetSubPixelWeight(float2 offset, float2 filterSize)
{
    // Note: when using fractional filter widths some samples should contribute zero. 
    if (any(abs(offset) > filterSize))
    {
        return 0.0f;
    }

#ifdef FILTER_GAUSSIAN
    offset *= 2.0f / filterSize;
    return exp(-2.0 * dot(offset, offset));
#endif

#ifdef FILTER_TRIANGLE
    float2 r = (1.0f - abs(offset)) / (0.5 * filterSize);
    return r.x * r.y;
#endif

#ifdef FILTER_CATMULLROM
    float r = dot(offset, offset);
    float r2 = sqrt(r);
    return (r >= 2.0f) ? 0.0f :
        (r < 1.0f) ? (3.0f * r * r2 - 5.0f * r2 + 2.0f) : (-r * r2 + 5.0f * r2 - 8.0f * r + 4.0f);
#endif

    return 1.0;
}

float2 UnpackFloat2(float r)
{
    uint bits = asuint(r);
    return float2(bits & 0xFFFF, bits >> 16) / 65535.0f;
}

[numthreads(8, 8, 1)]
void KMain(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);
    uint2 currentPixelCoord = dispatchThreadId.xy;

    float exposureMultiplier = (_AccumulationNeedsExposure != 0) ? GetCurrentExposureMultiplier() : 1.0;

    // Have we reached max sampling?
    uint sampleCount = _AccumulationFrameIndex;
    if (sampleCount >= _AccumulationNumSamples)
    {
        _CameraColorTextureRW[COORD_TEXTURE2D_X(currentPixelCoord)] = float4(_AccumulatedFrameTexture[COORD_TEXTURE2D_X(currentPixelCoord)].xyz * exposureMultiplier, 1.0);
    }
    else
    {
        float subFrameWeight = _AccumulationWeights.x;
        float4 accColor = sampleCount > 0 ? _AccumulatedFrameTexture[COORD_TEXTURE2D_X(currentPixelCoord)] : 0.0f;

        // Gather the contribution from all samples in the footprint of the reconstruction kernel
        // TODO: This loop can be easily optimized by using shader local storage
        const float2 filterRadius = _AccumulationWeights.yz;

        // Compute how many pixels we should traverse for the given radius: with a radius of 0.6, we already have to touch neightboring pixels
        int2 filterExtent = floor(filterRadius + 0.5f) + float2(1, 1); 
        for (int i = -filterExtent.x + 1; i < filterExtent.x; ++i)
        {
            for (int j = -filterExtent.y + 1; j < filterExtent.y; ++j)
            {
                int2 pixelCoords = currentPixelCoord + int2(i, j);
                pixelCoords = clamp(pixelCoords, 0, _ScreenSize.xy - float2(1, 1));

                float4 sampleColor = _RadianceTexture[COORD_TEXTURE2D_X(pixelCoords)];
                float2 sampleOffset = UnpackFloat2(sampleColor.w);
                float sampleWeight = GetSubPixelWeight(sampleOffset + float2(i, j) - float2(0.5f, 0.5f), 2 * filterRadius);

                // Also take into account motion blur (global subframe weights)
                sampleWeight *= subFrameWeight;

                float newAccWeight = accColor.w + sampleWeight;

                if (newAccWeight > 0)
                    sampleColor.xyz = (accColor.xyz * accColor.w + sampleWeight * sampleColor.xyz) / newAccWeight;

                accColor = float4(sampleColor.xyz, newAccWeight);
            }
        }

        _AccumulatedFrameTexture[COORD_TEXTURE2D_X(currentPixelCoord)] = accColor;

        // Apply exposure modifier
        accColor.xyz *= exposureMultiplier;

        // Add a little convergence cue to our result
        AddConvergenceCue(currentPixelCoord, sampleCount, accColor.xyz);

        _CameraColorTextureRW[COORD_TEXTURE2D_X(currentPixelCoord)] = float4(accColor.xyz, 1.0);
    }
}
